apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-agent-service-deployment
  namespace: selfmonitor
  labels:
    app: ai-agent-service
    component: ai
    version: "1.0.0"
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: ai-agent-service
      component: ai
  template:
    metadata:
      labels:
        app: ai-agent-service
        component: ai
        version: "1.0.0"
        type: service
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8010"
        prometheus.io/path: "/metrics"
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
      
      containers:
      - name: ai-agent
        image: selfmonitor/ai-agent-service:latest
        imagePullPolicy: IfNotPresent
        
        ports:
        - containerPort: 8010
          name: http
          protocol: TCP
        - containerPort: 9090
          name: metrics
          protocol: TCP
        
        env:
        # Database connections
        - name: POSTGRES_HOST
          value: "postgres-service"
        - name: POSTGRES_PORT
          value: "5432"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: POSTGRES_PASSWORD
        - name: POSTGRES_DB
          value: "db_ai_agent"
        
        # Redis connection
        - name: REDIS_HOST
          value: "redis-service"
        - name: REDIS_PORT
          value: "6379"
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: REDIS_PASSWORD
              optional: true
        
        # AI Configuration
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: OPENAI_API_KEY
        - name: OPENAI_MODEL
          value: "gpt-4-0125-preview"
        - name: OPENAI_TEMPERATURE
          value: "0.7"
        
        # Weaviate connection
        - name: WEAVIATE_URL
          value: "http://weaviate-service:8080"
        - name: WEAVIATE_API_KEY
          valueFrom:
            secretKeyRef:
              name: weaviate-secret
              key: WEAVIATE_API_KEY
              optional: true
        
        # Service discovery
        - name: AUTH_SERVICE_URL
          value: "http://auth-service:80"
        - name: USER_PROFILE_SERVICE_URL
          value: "http://user-profile-service:80"
        - name: TRANSACTIONS_SERVICE_URL
          value: "http://transactions-service:80"
        - name: ANALYTICS_SERVICE_URL
          value: "http://analytics-service:80"
        - name: ADVICE_SERVICE_URL
          value: "http://advice-service:80"
        - name: TAX_ENGINE_URL
          value: "http://tax-engine:80"
        - name: BANKING_CONNECTOR_URL
          value: "http://banking-connector:80"
        
        # Security
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: auth-secret
              key: JWT_SECRET_KEY
        - name: SERVICE_API_KEY
          valueFrom:
            secretKeyRef:
              name: service-secret
              key: API_KEY
        
        # Application configuration
        - name: ENVIRONMENT
          value: "production"
        - name: LOG_LEVEL
          value: "INFO"
        - name: DEBUG
          value: "false"
        - name: HOST
          value: "0.0.0.0"
        - name: PORT
          value: "8010"
        
        # Resource limits
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        
        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8010
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 10
          periodSeconds: 30
          successThreshold: 1
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8010
            scheme: HTTP
          initialDelaySeconds: 10
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        
        startupProbe:
          httpGet:
            path: /health
            port: 8010
            scheme: HTTP
          initialDelaySeconds: 30
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 12
      
      # Node scheduling preferences for AI workloads
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values:
                - ai
                - compute
          - weight: 50
            preference:
              matchExpressions:
              - key: kubernetes.io/arch
                operator: In
                values:
                - amd64
        
        # Spread across different nodes for availability
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - ai-agent-service
              topologyKey: kubernetes.io/hostname
      
      # Toleration for AI nodes with GPU
      tolerations:
      - key: "ai-node"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"

---
apiVersion: v1
kind: Service
metadata:
  name: ai-agent-service
  namespace: selfmonitor
  labels:
    app: ai-agent-service
    component: ai
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: 8010
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: 9090
    protocol: TCP
  selector:
    app: ai-agent-service
    component: ai
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 hours for conversation continuity

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-agent-service-hpa
  namespace: selfmonitor
  labels:
    app: ai-agent-service
    component: ai
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-agent-service-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60